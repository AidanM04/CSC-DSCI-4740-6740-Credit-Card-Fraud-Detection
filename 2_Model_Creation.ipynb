{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# File paths\n",
    "data_dir = \"./data\"\n",
    "\n",
    "# Loading data \n",
    "data_file = [\"credit_card_scaled_and_cleaned.csv\", \"balanced_credit_card.csv\", \"semi_balanced_credit_card.csv\"]\n",
    "file_path = os.path.join(data_dir, data_file[0])\n",
    "df = pd.read_csv(file_path, header=0)\n",
    "\n",
    "file_path = os.path.join(data_dir, data_file[1])\n",
    "balanced_df = pd.read_csv(file_path, header=0)\n",
    "\n",
    "file_path = os.path.join(data_dir, data_file[2])\n",
    "semi_balanced_df = pd.read_csv(file_path, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the Data into Training and Testing Sets\n",
    "Separate the Class attribute (target) from the rest of the features, and split the datasets into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split unbalanced dataset\n",
    "X_unbalanced = df.drop('Class', axis=1)\n",
    "y_unbalanced = df['Class']\n",
    "\n",
    "X_train_unbalanced, X_test_unbalanced, y_train_unbalanced, y_test_unbalanced = train_test_split(\n",
    "    X_unbalanced, y_unbalanced, test_size=0.3, stratify=y_unbalanced, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split balanced dataset\n",
    "X_balanced = balanced_df.drop('Class', axis=1)\n",
    "y_balanced = balanced_df['Class']\n",
    "\n",
    "X_train_balanced, X_test_balanced, y_train_balanced, y_test_balanced = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.3, stratify=y_balanced, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split semi balanced dataset\n",
    "X_semi_balanced = semi_balanced_df.drop('Class', axis=1)\n",
    "y_semi_balanced = semi_balanced_df['Class']\n",
    "\n",
    "X_train_semi_balanced, X_test_semi_balanced, y_train_semi_balanced, y_test_semi_balanced = train_test_split(\n",
    "    X_semi_balanced, y_semi_balanced, test_size=0.3, stratify=y_semi_balanced, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define Logistic Regression model and parameters\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_params = {\n",
    "    'C': [0.01, 0.1, 1, 10],        # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],        # Type of regularization\n",
    "    'solver': ['liblinear']         # Solver that supports L1 and L2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define SVM model and parameters\n",
    "svm_model = SVC(probability=True, random_state=42)  # Enable probability=True for ROC AUC\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],             # Regularization strength\n",
    "    'kernel': ['linear', 'rbf'],   # Kernel type\n",
    "    'gamma': ['scale', 'auto']     # Kernel coefficient\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define Random Forest model and parameters\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],   # Number of trees\n",
    "    'max_depth': [None, 10, 20],      # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5],      # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2]        # Minimum samples in a leaf node\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Scoring Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, pos_label=1),\n",
    "    'recall': make_scorer(recall_score, pos_label=1),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score, response_method='predict_proba')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Stratified K-Fold cross-validator:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA COMMENT:\n",
    "    I'm adding extra parameters to the train with kfold function, these beiing X_train and y_train. These placeholders will replace the values placed in grid.fit previously so we can easily run the train with kfold function on the other datasets to see the optimal hyperparameters for those datasets. I have edited all of the code in this block to use this new functionality and commented out rather than deleting the original grid.fit line so you can see what I'm talking about. I've edited all the code currently in this .ipynb file to use this new formatting and added the six lines at the bottom of the block below to attempt to run the train_with_kfold function on the other datasets. Notably I havent tested this code yet or made the cross validation improvements table for these new datasets.\n",
    "\n",
    "    From here, our next steps for this .ipynb file are to move the defining of the evaluate_on_whatever functions into this file. It may be easier to run them in the results_and_visualizations.ipynb file though. Since this isnt a regular python file, we wont be able to import the functions directly into results_and_visualizations.ipynb so we may have to use the nbimporter pip package to import the finished functions from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Logistic Regression Cross-Validation Results:\n",
      "Best Parameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy: Top=0.9433, Lowest=0.7820, Difference=0.1614\n",
      "Precision: Top=0.9781, Lowest=0.7085, Difference=0.2696\n",
      "Recall: Top=0.9594, Lowest=0.9012, Difference=0.0582\n",
      "F1: Top=0.9416, Lowest=0.8148, Difference=0.1268\n",
      "Roc_auc: Top=0.9852, Lowest=0.9637, Difference=0.0214\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Support Vector Machine (SVM) Cross-Validation Results:\n",
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: Top=0.9462, Lowest=0.9128, Difference=0.0335\n",
      "Precision: Top=0.9902, Lowest=0.9039, Difference=0.0863\n",
      "Recall: Top=0.9302, Lowest=0.8460, Difference=0.0843\n",
      "F1: Top=0.9437, Lowest=0.9115, Difference=0.0322\n",
      "Roc_auc: Top=0.9825, Lowest=0.9666, Difference=0.0159\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "Random Forest Cross-Validation Results:\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Accuracy: Top=0.9375, Lowest=0.9303, Difference=0.0073\n",
      "Precision: Top=0.9779, Lowest=0.9683, Difference=0.0096\n",
      "Recall: Top=0.8954, Lowest=0.8896, Difference=0.0058\n",
      "F1: Top=0.9345, Lowest=0.9269, Difference=0.0076\n",
      "Roc_auc: Top=0.9782, Lowest=0.9756, Difference=0.0026\n"
     ]
    }
   ],
   "source": [
    "## Are these just trained for generally best params or are they trained to have the best params for the data? \n",
    "## I feel like we should attempt to train these for our dataset(s) specifically if (if they arent already) so as to get the best results.\n",
    "## I don't think it's too big a deal though, Our current models are pretty alright (I think)\n",
    "\n",
    "def train_with_kfold(model, params, model_name, X_train, y_train):\n",
    "    grid = GridSearchCV(\n",
    "        model,\n",
    "        params,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        scoring=scoring,\n",
    "        refit='accuracy',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    #grid.fit(X_train_balanced, y_train_balanced)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Extract cross-validation results\n",
    "    cv_results = grid.cv_results_\n",
    "    improvements = []\n",
    "\n",
    "    print(f\"\\n{model_name} Cross-Validation Results:\")\n",
    "    print(f\"Best Parameters: {grid.best_params_}\")\n",
    "\n",
    "    # Calculate improvements for each metric\n",
    "    for metric in scoring.keys():\n",
    "        metric_scores = cv_results[f'mean_test_{metric}']\n",
    "        top_score = metric_scores.max()\n",
    "        lowest_score = metric_scores.min()\n",
    "        improvements.append({\n",
    "            \"Metric\": metric.capitalize(),\n",
    "            \"Top Score\": top_score,\n",
    "            \"Lowest Score\": lowest_score,\n",
    "            \"Difference\": top_score - lowest_score\n",
    "        })\n",
    "        print(f\"{metric.capitalize()}: Top={top_score:.4f}, Lowest={lowest_score:.4f}, Difference={top_score - lowest_score:.4f}\")\n",
    "    \n",
    "    # Return the trained model and improvements\n",
    "    return grid.best_estimator_, pd.DataFrame(improvements)\n",
    "\n",
    "# Train each model on with each dataset\n",
    "best_lr_balanced, lr_improvements_balanced = train_with_kfold(lr_model, lr_params, \"Logistic Regression\", X_train_balanced, y_train_balanced)\n",
    "best_svm_balanced, svm_improvements_balanced = train_with_kfold(svm_model, svm_params, \"Support Vector Machine (SVM)\", X_train_balanced, y_train_balanced)\n",
    "best_rf_balanced, rf_improvements_balanced = train_with_kfold(rf_model, rf_params, \"Random Forest\", X_train_balanced, y_train_balanced)\n",
    "\n",
    "best_lr_unbalanced, lr_improvements_unbalanced = train_with_kfold(lr_model, lr_params, \"Logistic Regression\", X_train_unbalanced, y_train_unbalanced)\n",
    "best_svm_unbalanced, svm_improvements_unbalanced = train_with_kfold(svm_model, svm_params, \"Support Vector Machine (SVM)\", X_train_unbalanced, y_train_unbalanced)\n",
    "best_rf_unbalanced, rf_improvements_unbalanced = train_with_kfold(rf_model, rf_params, \"Random Forest\", X_train_unbalanced, y_train_unbalanced)\n",
    "\n",
    "best_lr_semi_balanced, lr_improvements_semi_balanced = train_with_kfold(lr_model, lr_params, \"Logistic Regression\", X_train_semi_balanced, y_train_semi_balanced)\n",
    "best_svm_semi_balanced, svm_improvements_semi_balanced = train_with_kfold(svm_model, svm_params, \"Support Vector Machine (SVM)\", X_train_semi_balanced, y_train_semi_balanced)\n",
    "best_rf_semi_balanced, rf_improvements_semi_balanced = train_with_kfold(rf_model, rf_params, \"Random Forest\", X_train_semi_balanced, y_train_semi_balanced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Improvements Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Improvements:\n",
      "Logistic Regression Improvements:\n",
      "       Metric  Top Score  Lowest Score  Difference\n",
      "0   Accuracy   0.943330      0.781974    0.161356\n",
      "1  Precision   0.978102      0.708533    0.269568\n",
      "2     Recall   0.959378      0.901151    0.058227\n",
      "3         F1   0.941632      0.814850    0.126782\n",
      "4    Roc_auc   0.985169      0.963721    0.021448\n",
      "SVM Improvements:\n",
      "       Metric  Top Score  Lowest Score  Difference\n",
      "0   Accuracy   0.946250      0.912779    0.033471\n",
      "1  Precision   0.990206      0.903868    0.086339\n",
      "2     Recall   0.930222      0.845951    0.084271\n",
      "3         F1   0.943685      0.911489    0.032196\n",
      "4    Roc_auc   0.982480      0.966610    0.015870\n",
      "Random Forest Improvements:\n",
      "       Metric  Top Score  Lowest Score  Difference\n",
      "0   Accuracy   0.937544      0.930276    0.007268\n",
      "1  Precision   0.977894      0.968325    0.009569\n",
      "2     Recall   0.895354      0.889557    0.005797\n",
      "3         F1   0.934498      0.926919    0.007580\n",
      "4    Roc_auc   0.978219      0.975627    0.002592\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCross-Validation Improvements:\")\n",
    "print(\"Logistic Regression Improvements:\\n\", lr_improvements_balanced)\n",
    "print(\"SVM Improvements:\\n\", svm_improvements_balanced)\n",
    "print(\"Random Forest Improvements:\\n\", rf_improvements_balanced)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
