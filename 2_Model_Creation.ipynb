{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# File paths\n",
    "data_dir = \"./data\"\n",
    "\n",
    "# Loading data \n",
    "data_file = [\"credit_card_scaled_and_cleaned.csv\", \"balanced_credit_card.csv\", \"semi_balanced_credit_card.csv\"]\n",
    "file_path = os.path.join(data_dir, data_file[0])\n",
    "df = pd.read_csv(file_path, header=0)\n",
    "\n",
    "file_path = os.path.join(data_dir, data_file[1])\n",
    "balanced_df = pd.read_csv(file_path, header=0)\n",
    "\n",
    "file_path = os.path.join(data_dir, data_file[2])\n",
    "semi_balanced_df = pd.read_csv(file_path, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the Data into Training and Testing Sets\n",
    "Separate the Class attribute (target) from the rest of the features, and split the dataset into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split balanced dataset\n",
    "X_balanced = balanced_df.drop('Class', axis=1)\n",
    "y_balanced = balanced_df['Class']\n",
    "\n",
    "X_train_balanced, X_test_balanced, y_train_balanced, y_test_balanced = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.3, stratify=y_balanced, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define Logistic Regression model and parameters\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_params = {\n",
    "    'C': [0.01, 0.1, 1, 10],        # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],        # Type of regularization\n",
    "    'solver': ['liblinear']         # Solver that supports L1 and L2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define SVM model and parameters\n",
    "svm_model = SVC(probability=True, random_state=42)  # Enable probability=True for ROC AUC\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],             # Regularization strength\n",
    "    'kernel': ['linear', 'rbf'],   # Kernel type\n",
    "    'gamma': ['scale', 'auto']     # Kernel coefficient\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define Random Forest model and parameters\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],   # Number of trees\n",
    "    'max_depth': [None, 10, 20],      # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5],      # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2]        # Minimum samples in a leaf node\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Scoring Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, pos_label=1),\n",
    "    'recall': make_scorer(recall_score, pos_label=1),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score, response_method='predict_proba')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Stratified K-Fold cross-validator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Logistic Regression Cross-Validation Results:\n",
      "Best Parameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy: Top=0.9433, Lowest=0.7820, Difference=0.1614\n",
      "Precision: Top=0.9781, Lowest=0.7085, Difference=0.2696\n",
      "Recall: Top=0.9594, Lowest=0.9012, Difference=0.0582\n",
      "F1: Top=0.9416, Lowest=0.8148, Difference=0.1268\n",
      "Roc_auc: Top=0.9852, Lowest=0.9637, Difference=0.0214\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Support Vector Machine (SVM) Cross-Validation Results:\n",
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: Top=0.9462, Lowest=0.9128, Difference=0.0335\n",
      "Precision: Top=0.9902, Lowest=0.9039, Difference=0.0863\n",
      "Recall: Top=0.9302, Lowest=0.8460, Difference=0.0843\n",
      "F1: Top=0.9437, Lowest=0.9115, Difference=0.0322\n",
      "Roc_auc: Top=0.9825, Lowest=0.9666, Difference=0.0159\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "Random Forest Cross-Validation Results:\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Accuracy: Top=0.9375, Lowest=0.9303, Difference=0.0073\n",
      "Precision: Top=0.9779, Lowest=0.9683, Difference=0.0096\n",
      "Recall: Top=0.8954, Lowest=0.8896, Difference=0.0058\n",
      "F1: Top=0.9345, Lowest=0.9269, Difference=0.0076\n",
      "Roc_auc: Top=0.9782, Lowest=0.9756, Difference=0.0026\n"
     ]
    }
   ],
   "source": [
    "## Are these just trained for generally best params or are they trained to have the best params for the data? \n",
    "## I feel like we should attempt to train these for our dataset(s) specifically if (if they arent already) so as to get the best results.\n",
    "## I don't think it's too big a deal though, Our current models are pretty alright (I think)\n",
    "\n",
    "def train_with_kfold(model, params, model_name):\n",
    "    grid = GridSearchCV(\n",
    "        model,\n",
    "        params,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        scoring=scoring,\n",
    "        refit='accuracy',\n",
    "        verbose=1\n",
    "    )\n",
    "    grid.fit(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # Extract cross-validation results\n",
    "    cv_results = grid.cv_results_\n",
    "    improvements = []\n",
    "\n",
    "    print(f\"\\n{model_name} Cross-Validation Results:\")\n",
    "    print(f\"Best Parameters: {grid.best_params_}\")\n",
    "\n",
    "    # Calculate improvements for each metric\n",
    "    for metric in scoring.keys():\n",
    "        metric_scores = cv_results[f'mean_test_{metric}']\n",
    "        top_score = metric_scores.max()\n",
    "        lowest_score = metric_scores.min()\n",
    "        improvements.append({\n",
    "            \"Metric\": metric.capitalize(),\n",
    "            \"Top Score\": top_score,\n",
    "            \"Lowest Score\": lowest_score,\n",
    "            \"Difference\": top_score - lowest_score\n",
    "        })\n",
    "        print(f\"{metric.capitalize()}: Top={top_score:.4f}, Lowest={lowest_score:.4f}, Difference={top_score - lowest_score:.4f}\")\n",
    "    \n",
    "    # Return the trained model and improvements\n",
    "    return grid.best_estimator_, pd.DataFrame(improvements)\n",
    "\n",
    "# Train each model\n",
    "best_lr, lr_improvements = train_with_kfold(lr_model, lr_params, \"Logistic Regression\")\n",
    "best_svm, svm_improvements = train_with_kfold(svm_model, svm_params, \"Support Vector Machine (SVM)\")\n",
    "best_rf, rf_improvements = train_with_kfold(rf_model, rf_params, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Improvements Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Improvements:\n",
      "Logistic Regression Improvements:\n",
      "       Metric  Top Score  Lowest Score  Difference\n",
      "0   Accuracy   0.943330      0.781974    0.161356\n",
      "1  Precision   0.978102      0.708533    0.269568\n",
      "2     Recall   0.959378      0.901151    0.058227\n",
      "3         F1   0.941632      0.814850    0.126782\n",
      "4    Roc_auc   0.985169      0.963721    0.021448\n",
      "SVM Improvements:\n",
      "       Metric  Top Score  Lowest Score  Difference\n",
      "0   Accuracy   0.946250      0.912779    0.033471\n",
      "1  Precision   0.990206      0.903868    0.086339\n",
      "2     Recall   0.930222      0.845951    0.084271\n",
      "3         F1   0.943685      0.911489    0.032196\n",
      "4    Roc_auc   0.982480      0.966610    0.015870\n",
      "Random Forest Improvements:\n",
      "       Metric  Top Score  Lowest Score  Difference\n",
      "0   Accuracy   0.937544      0.930276    0.007268\n",
      "1  Precision   0.977894      0.968325    0.009569\n",
      "2     Recall   0.895354      0.889557    0.005797\n",
      "3         F1   0.934498      0.926919    0.007580\n",
      "4    Roc_auc   0.978219      0.975627    0.002592\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCross-Validation Improvements:\")\n",
    "print(\"Logistic Regression Improvements:\\n\", lr_improvements)\n",
    "print(\"SVM Improvements:\\n\", svm_improvements)\n",
    "print(\"Random Forest Improvements:\\n\", rf_improvements)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
